import pandas as pd
import numpy as np
import math
import scipy.stats as st
from sklearn.preprocessing import MinMaxScaler

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.width', 500)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('display.float_format', lambda x: '%.5f' % x)

df = pd.read_csv("amazon_review.csv")
a = pd.read_csv("amazon_review.csv")
df = df[["overall", "reviewTime", "day_diff", "helpful_yes", "total_vote"]]
df.head()

#################
# GÖREV 1
#################

# Adım 1
df["overall"].mean()  # 4.58758

# Adım 2
df["reviewTime"] = pd.to_datetime(df["reviewTime"])
current_date = df["reviewTime"].max()
df["day_diff"] = (current_date - df["reviewTime"]).dt.days
df["day_diff"].quantile([.25, .5, .75])  # .25 => 280, .50 => 430, .75 => 600


def time_based_weighted_average(dataframe, w1=28, w2=26, w3=24, w4=22):
    return dataframe.loc[(dataframe["day_diff"] <= 280), "overall"].mean() * w1 / 100 + \
           dataframe.loc[(dataframe["day_diff"] > 280) & (dataframe["day_diff"] <= 430), "overall"].mean() * w2 / 100 + \
           dataframe.loc[(dataframe["day_diff"] > 430) & (dataframe["day_diff"] <= 600), "overall"].mean() * w3 / 100 + \
           dataframe.loc[(dataframe["day_diff"] > 600), "overall"].mean() * w4 / 100


time_based_weighted_average(df)  # 4.5955

df.loc[(df["day_diff"] <= 280), "overall"].mean()  # 4.695
df.loc[(df["day_diff"] > 280) & (df["day_diff"] <= 430), "overall"].mean()  # 4.636
df.loc[(df["day_diff"] > 430) & (df["day_diff"] <= 600), "overall"].mean()  # 4.571
df.loc[(df["day_diff"] > 600), "overall"].mean()  # 4.446
# Yani zaman geçtikçe ve günümüze geldikçe verilen puanlar artmış, zamanla memnuniyet trendinde artış olmuştur.


#################
# GÖREV 2
#################

# Adım 1
df["helpful_no"] = df["total_vote"] - df["helpful_yes"]


# Adım 2
def score_pos_neg_diff(up, down):
    return up - down


def score_average_rating(up, down):
    if up + down == 0:
        return 0
    return up / (up + down)


def wilson_lower_bound(up, down, confidence=0.95):
    n = up + down
    if n == 0:
        return 0
    z = st.norm.ppf(1 - (1 - confidence) / 2)
    phat = 1.0 * up / n
    return (phat + z * z / (2 * n) - z * math.sqrt((phat * (1 - phat) + z * z / (4 * n)) / n)) / (1 + z * z / n)


df["score_pos_neg_diff"] = score_pos_neg_diff(df["helpful_yes"], df["helpful_no"])
df["score_average_rating"] = df.apply(lambda x: score_average_rating(x["helpful_yes"], x["helpful_no"]), axis=1)
df["wilson_lower_bound"] = df.apply(lambda x: wilson_lower_bound(x["helpful_yes"], x["helpful_no"]), axis=1)


# wilson = []
# for i in range(df.shape[0]):
#     wilson.append(wilson_lower_bound(df.loc[i, "helpful_yes"], df.loc[i, "helpful_no"]))
#
# wilson = np.array(wilson)
# df["wilson_lower_bound"] = wilson


df.sort_values("score_average_rating", ascending=False).head(20)
df.sort_values("wilson_lower_bound", ascending=False).head(20)


# dataset: https://www.kaggle.com/datasets/halimedogan/amazon-reviews
